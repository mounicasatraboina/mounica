{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mounicasatraboina/mounica/blob/main/INFO5731_Assignment_Two/INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(20 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [Apple iPhone 11](https://www.amazon.com/Apple-iPhone-11-64GB-Unlocked/dp/B07ZPKF8RG/ref=sr_1_13?dchild=1&keywords=iphone+12&qid=1631721363&sr=8-13) on amazon.\n",
        "\n",
        "(2) Collect all User Reviews of the film [Shang-Chi and the Legend of the Ten Rings](https://www.imdb.com/title/tt9376612/reviews?ref_=tt_sa_3) from IMDB.\n",
        "\n",
        "(3) Collect all the abstracts research papers by using the query [smart health](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(4) Collect the top 10,000 tweets by using hashtag [\"#blacklivesmatter\"](https://twitter.com/hashtag/blacklivesmatter) from Twitter with the following requirements: Location (Texas), Time frame (2021-01-01 to 2021-09-01). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuFPKhC0m1fd",
        "outputId": "bcb26b25-5339-419d-8f6e-f0403f494908"
      },
      "source": [
        "# Write your code here\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "import requests as rq\n",
        "\n",
        "# Below is the code which extracts amazon reviews\n",
        "def imdb_webscraper(link):\n",
        "    df = pd.DataFrame(columns=['User name', 'Star', 'Review title', 'Review text', 'Review posted time'])\n",
        "    req = rq.get(link).text\n",
        "    soup = bs(req,'html.parser')\n",
        "\n",
        "    user_names = soup.find_all('span', attrs={'class' : 'display-name-link'})\n",
        "    star = soup.find_all('span', attrs={'class' : 'rating-other-user-rating'})\n",
        "    review_title = soup.find_all('a', attrs={'class' : 'title'})\n",
        "    review_text = soup.find_all('div', attrs={'class' : 'text show-more__control'})\n",
        "    review_posted_time = soup.find_all('span', attrs={'class' : 'review-date'})\n",
        "\n",
        "    list = []\n",
        "    for i in range(len(user_names)):\n",
        "        list.append(user_names[i].get_text())\n",
        "    df['User name'] = list\n",
        "\n",
        "    \"\"\"list = []\n",
        "    for i in range(len(star)):\n",
        "        list.append(star[i].get_text()[6])\n",
        "    df['Star'] = list\"\"\"\n",
        "\n",
        "    list = []\n",
        "    for i in range(len(review_title)):\n",
        "        list.append(review_title[i].get_text())\n",
        "    df['Review title'] = list\n",
        "\n",
        "    list = []\n",
        "    for i in range(len(review_text)):\n",
        "        list.append(review_text[i].get_text())\n",
        "    df['Review text'] = list\n",
        "\n",
        "    list = []\n",
        "    for i in range(len(review_posted_time)):\n",
        "        list.append(review_posted_time[i].get_text())\n",
        "    df['Review posted time'] = list\n",
        "    print(df.head())\n",
        "    df.to_csv(\"output.csv\")\n",
        "\n",
        "imdb_webscraper('https://www.imdb.com/title/tt9376612/reviews?ref_=tt_sa_3')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          User name  ... Review posted time\n",
            "0                 dominicwood-14504  ...   4 September 2021\n",
            "1                     laviniadallam  ...   2 September 2021\n",
            "2  Radio-1s_Mr-MovieMad-Ami_104-1FM  ...   8 September 2021\n",
            "3                      mhatreritesh  ...   4 September 2021\n",
            "4                 nishantsalhotrans  ...   6 September 2021\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points) Here is a [legal case](https://github.com/unt-iialab/info5731-fall2021/blob/main/assignments/01-05-1%20%20Adams%20v%20Tanner.txt) we collected from westlaw, please follow the steps we mentioned in lesson 5 to clean the data:\n",
        "\n",
        "\n",
        "\n",
        "(1) Basic feature extraction using text data\n",
        "\n",
        "*   Number of sentences\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average word length\n",
        "*   Number of stopwords\n",
        "*   Number of special characters\n",
        "*   Number of numerics\n",
        "*   Number of uppercase words\n",
        "\n",
        "(2) Basic Text Pre-processing of text data\n",
        "\n",
        "*   Lower casing\n",
        "*   Punctuation removal\n",
        "*   Stopwords removal\n",
        "*   Frequent words removal\n",
        "*   Rare words removal\n",
        "*   Spelling correction\n",
        "*   Tokenization\n",
        "*   Stemming\n",
        "*   Lemmatization\n",
        "\n",
        "(3) Save all the **clean sentences** to a **csv file** (one column, each raw is a sentence) after finishing all the steps above.\n",
        "\n",
        "\n",
        "(4) Advance Text Processing\n",
        "\n",
        "*   Calculate the term frequency of all the terms.\n",
        "*   Print out top 10 1-gram, top 10 2-grams, and top 10 3-grams terms as features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyqL7BDosWaS",
        "outputId": "72a102ba-c83c-459c-b5c9-84b2a5cb028e"
      },
      "source": [
        "# Number of Sentences\n",
        "import pandas as pd\n",
        "results = pd.read_csv('assign2.csv',encoding='ISO-8859-1')\n",
        "print(\"Number of Sentences  present:-\", \n",
        "      len(results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Sentences  present:- 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "NkW9gz5bdKKA",
        "outputId": "2e410364-3c75-4103-d2d1-ae0a661d8ca4"
      },
      "source": [
        "#Number of words\n",
        "import pandas as pd\n",
        "data_url = \"assign2.csv\"\n",
        "train = pd.read_csv(data_url,encoding='ISO-8859-1')\n",
        "train['word_count'] = train['legal_documents'].apply(lambda x: len(str(x).split(\" \")))\n",
        "train[['legal_documents','word_count']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TANNER AND HORTON</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>June Term, 1843.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             legal_documents  word_count\n",
              "0  Supreme Court of Alabama.           4\n",
              "1                      ADAMS           1\n",
              "2                         v.           1\n",
              "3          TANNER AND HORTON           3\n",
              "4           June Term, 1843.           3"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "g7KYg4CEeXIe",
        "outputId": "fe6c6ae8-d040-4273-d6fe-009164f4fdda"
      },
      "source": [
        "#Number of characters\n",
        "train['char_count'] = train['legal_documents'].str.len()  ## this also includes spaces\n",
        "train[['legal_documents','char_count']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TANNER AND HORTON</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>June Term, 1843.</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             legal_documents  char_count\n",
              "0  Supreme Court of Alabama.          25\n",
              "1                      ADAMS           5\n",
              "2                         v.           2\n",
              "3          TANNER AND HORTON          17\n",
              "4           June Term, 1843.          16"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "NsdtMKdleuXk",
        "outputId": "371df60f-f080-4165-c976-478d677da354"
      },
      "source": [
        "#avearge word length\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  return (sum(len(word) for word in words)/len(words))\n",
        "\n",
        "train['avg_word'] = train['legal_documents'].apply(lambda x: avg_word(x))\n",
        "train[['legal_documents','avg_word']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>avg_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TANNER AND HORTON</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>June Term, 1843.</td>\n",
              "      <td>4.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             legal_documents  avg_word\n",
              "0  Supreme Court of Alabama.  5.500000\n",
              "1                      ADAMS  5.000000\n",
              "2                         v.  2.000000\n",
              "3          TANNER AND HORTON  5.000000\n",
              "4           June Term, 1843.  4.666667"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "lksBuAIle_45",
        "outputId": "fdc23830-91c0-4217-be77-90f44b563baf"
      },
      "source": [
        "#number of stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "train['stopwords'] = train['legal_documents'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
        "train[['legal_documents','stopwords']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TANNER AND HORTON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>June Term, 1843.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             legal_documents  stopwords\n",
              "0  Supreme Court of Alabama.          1\n",
              "1                      ADAMS          0\n",
              "2                         v.          0\n",
              "3          TANNER AND HORTON          0\n",
              "4           June Term, 1843.          0"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "gaBPSc8ifSiq",
        "outputId": "bbc6f61e-5aef-4ffd-d85f-856778a3dc1b"
      },
      "source": [
        "#number of special characters\n",
        "train['hastags'] = train['legal_documents'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
        "train[['legal_documents','hastags']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>hastags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TANNER AND HORTON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>June Term, 1843.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             legal_documents  hastags\n",
              "0  Supreme Court of Alabama.        0\n",
              "1                      ADAMS        0\n",
              "2                         v.        0\n",
              "3          TANNER AND HORTON        0\n",
              "4           June Term, 1843.        0"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "P_OpsjhjfleD",
        "outputId": "291a42f5-a1e9-4250-a8d9-0ad66856fd9e"
      },
      "source": [
        "#number of numerics\n",
        "train['numerics'] = train['legal_documents'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "train[['legal_documents','numerics']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>numerics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TANNER AND HORTON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>June Term, 1843.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             legal_documents  numerics\n",
              "0  Supreme Court of Alabama.         0\n",
              "1                      ADAMS         0\n",
              "2                         v.         0\n",
              "3          TANNER AND HORTON         0\n",
              "4           June Term, 1843.         0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "W_AH9gpSfyiC",
        "outputId": "72573e70-1677-4fcf-c9f6-df0daae290cd"
      },
      "source": [
        "#number of uppercase words\n",
        "train['upper'] = train['legal_documents'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "train[['legal_documents','upper']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>upper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TANNER AND HORTON</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>June Term, 1843.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             legal_documents  upper\n",
              "0  Supreme Court of Alabama.      0\n",
              "1                      ADAMS      1\n",
              "2                         v.      0\n",
              "3          TANNER AND HORTON      3\n",
              "4           June Term, 1843.      0"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "yJpEKb4df6AL",
        "outputId": "e35235bf-5c79-42d8-8958-beda22d01701"
      },
      "source": [
        "#lower casing\n",
        "train['Lower'] = train['legal_documents'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "train[['legal_documents','Lower']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>legal_documents</th>\n",
              "      <th>Lower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supreme alabama</td>\n",
              "      <td>supreme alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adam</td>\n",
              "      <td>adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tanner horton</td>\n",
              "      <td>tanner horton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>june term 1843</td>\n",
              "      <td>june term 1843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   legal_documents            Lower\n",
              "0  supreme alabama  supreme alabama\n",
              "1             adam             adam\n",
              "2                                  \n",
              "3    tanner horton    tanner horton\n",
              "4   june term 1843   june term 1843"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGcO_oGegSt5",
        "outputId": "8a3e057a-6682-4452-caf6-f3df182c8d88"
      },
      "source": [
        "#punctuation removal\n",
        "train['legal_documents'] = train['legal_documents'].str.replace('[^\\w\\s]','')\n",
        "train['legal_documents'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    supreme alabama\n",
              "1               adam\n",
              "2                   \n",
              "3      tanner horton\n",
              "4     june term 1843\n",
              "Name: legal_documents, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkp3sez3gpzZ",
        "outputId": "ada7df2a-8a39-43a7-9553-2e85b2f46dd3"
      },
      "source": [
        "#stopwords removal\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "train['legal_documents'] = train['legal_documents'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "train['legal_documents'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    supreme alabama\n",
              "1               adam\n",
              "2                   \n",
              "3      tanner horton\n",
              "4     june term 1843\n",
              "Name: legal_documents, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u-2x4Bdg5Wm",
        "outputId": "1f8f9275-fd30-4a42-8efe-7db356837f34"
      },
      "source": [
        "#frequent word removal\n",
        "freq = pd.Series('.'.join(train['legal_documents']).split()).value_counts()[:10]\n",
        "freq\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rep           16\n",
              "growing       16\n",
              "case          16\n",
              "law           15\n",
              "ala           14\n",
              "cotton        14\n",
              "plaintiff     14\n",
              "possession    13\n",
              "sale          13\n",
              "may           12\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYxrJ65aiM-K",
        "outputId": "5a701cb9-7266-4573-fb88-100d65568048"
      },
      "source": [
        "\n",
        "\n",
        "train['legal_documents'] = train['legal_documents'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
        "train['legal_documents'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    supreme alabama\n",
              "1               adam\n",
              "2                   \n",
              "3      tanner horton\n",
              "4     june term 1843\n",
              "Name: legal_documents, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIm-LTH0jOSy",
        "outputId": "b887efb0-6701-43ba-836b-b30708520d74"
      },
      "source": [
        "#rare words removal\n",
        "freq = pd.Series(' '.join(train['legal_documents']).split()).value_counts()[-10:]\n",
        "freq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "see         1\n",
              "practice    1\n",
              "1871        1\n",
              "learned     1\n",
              "recites     1\n",
              "145         1\n",
              "supra       1\n",
              "ormond      1\n",
              "follow      1\n",
              "doubted     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhzUo47Tja00",
        "outputId": "32f5b982-7c00-4fb2-b294-5005f8abf84f"
      },
      "source": [
        "\n",
        "\n",
        "train['legal_documents'] = train['legal_documents'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
        "train['legal_documents'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    supreme alabama\n",
              "1               adam\n",
              "2                   \n",
              "3      tanner horton\n",
              "4     june term 1843\n",
              "Name: legal_documents, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVIxgLJtkMF3",
        "outputId": "76d1954e-7333-43b7-b4f0-bf4509fc4e27"
      },
      "source": [
        "#spelling correction\n",
        "from textblob import TextBlob\n",
        "train['legal_documents'][:5].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    supreme alabama\n",
              "1               adam\n",
              "2                   \n",
              "3      manner norton\n",
              "4     june term 1843\n",
              "Name: legal_documents, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ6smUqWkS3f",
        "outputId": "08707c15-0411-47dd-bf20-b14edfd96ab6"
      },
      "source": [
        "#tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "TextBlob(train['legal_documents'][1]).words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['adam'])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_4ZjKOYkhD3",
        "outputId": "9de7f664-8e05-40e0-fe0f-5ff3e878b219"
      },
      "source": [
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "train['legal_documents'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    suprem alabama\n",
              "1              adam\n",
              "2                  \n",
              "3     tanner horton\n",
              "4    june term 1843\n",
              "Name: legal_documents, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkxEQ0SHkpPn",
        "outputId": "fa56a234-0b46-45ee-ef91-eb96290f3f48"
      },
      "source": [
        "#lemmatization\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "train['legal_documents'] = train['legal_documents'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "train['legal_documents'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    supreme alabama\n",
              "1               adam\n",
              "2                   \n",
              "3      tanner horton\n",
              "4     june term 1843\n",
              "Name: legal_documents, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBdPewbHlc4v",
        "outputId": "41040cf3-d321-41cc-f2e2-267d35004cdb"
      },
      "source": [
        "#  saving the output in csv file\n",
        "train.to_csv(\"assign2_output.csv\")\n",
        "print(train.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   legal_documents  word_count  char_count  ...  numerics  upper            Lower\n",
            "0  supreme alabama           4          25  ...         0      0  supreme alabama\n",
            "1             adam           1           5  ...         0      1             adam\n",
            "2                            1           2  ...         0      0                 \n",
            "3    tanner horton           3          17  ...         0      3    tanner horton\n",
            "4   june term 1843           3          16  ...         0      0   june term 1843\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "uly85D3opEWk",
        "outputId": "c26e64d3-6212-4e21-9d1a-87df6ae99a02"
      },
      "source": [
        "#Calculate the term frequency of all the terms.\n",
        "tf1 = (train['legal_documents'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
        "tf1.columns = ['words','tf']\n",
        "tf1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>tf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adam</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  words  tf\n",
              "0  adam   1"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTJ_wfFc_9I0"
      },
      "source": [
        "Print out top 10 1-gram, top 10 2-grams, and top 10 3-grams terms as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRiV8ngIrRVI",
        "outputId": "fc66f566-812d-4813-820a-05bd96f16b67"
      },
      "source": [
        "# One - gram\n",
        "ngram=TextBlob(train['legal_documents'][0]).ngrams(1)\n",
        "ngram[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['supreme']), WordList(['alabama'])]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2BDdkdCr3rB",
        "outputId": "bbf1f709-72e9-45ef-e22e-2dd7dfdd858a"
      },
      "source": [
        "# two - gram\n",
        "ngram=TextBlob(train['legal_documents'][0]).ngrams(2)\n",
        "ngram[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['supreme', 'alabama'])]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO5k6xiKsBnd",
        "outputId": "c02dd5ce-2a10-4072-d053-c614f48e2a5f"
      },
      "source": [
        "# three- gram\n",
        "ngram=TextBlob(train['legal_documents'][0]).ngrams(3)\n",
        "ngram[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960be6c8-7443-4223-b260-4dc43d7775fb"
      },
      "source": [
        "#Parts of Speech (POS) Tagging\n",
        "\n",
        "# 3.1 Parts Of Speech (POS) Tagging\n",
        "import spacy\n",
        "nltk.download('punkt')\n",
        "from spacy import displacy\n",
        "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lps57Uoy8jL",
        "outputId": "488f993b-3dee-4da0-e4d1-027918dbc1f0"
      },
      "source": [
        "# Tagging: Tag Parts of Speech of each word in the tex\n",
        "from nltk.tokenize import word_tokenize\n",
        "pos = []\n",
        "for statement in train['Lower']:\n",
        "  text = word_tokenize(statement)\n",
        "  pos.append(nltk.pos_tag(text))\n",
        "pos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('supreme', 'NN'), ('alabama', 'NN')],\n",
              " [('adam', 'NN')],\n",
              " [],\n",
              " [('tanner', 'NN'), ('horton', 'NN')],\n",
              " [('june', 'JJ'), ('term', 'NN'), ('1843', 'CD')],\n",
              " [('synopsis', 'NN')],\n",
              " [('writ', 'NN'), ('error', 'NN'), ('circuit', 'NN'), ('sumter', 'NN')],\n",
              " [('west', 'NN'), ('headnotes', 'VBZ'), ('2', 'CD')],\n",
              " [('1', 'CD'),\n",
              "  ('chattel', 'NN'),\n",
              "  ('mortgage', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('existence', 'NN'),\n",
              "  ('subjectmatter', 'NN'),\n",
              "  ('mortgage', 'NN'),\n",
              "  ('pass', 'NN'),\n",
              "  ('interest', 'NN'),\n",
              "  ('vest', 'NN'),\n",
              "  ('possession', 'NN'),\n",
              "  ('either', 'CC'),\n",
              "  ('immediately', 'RB'),\n",
              "  ('future', 'JJ'),\n",
              "  ('time', 'NN')],\n",
              " [('4', 'CD'), ('case', 'NN'), ('cite', 'JJ'), ('headnote', 'NN')],\n",
              " [('2', 'CD'),\n",
              "  ('creditor', 'NN'),\n",
              "  ('remedy', 'NN'),\n",
              "  ('priority', 'NN'),\n",
              "  ('st1821', 'NN'),\n",
              "  ('prohibiting', 'VBG'),\n",
              "  ('attache', 'NN'),\n",
              "  ('favor', 'NN'),\n",
              "  ('fi', 'JJ'),\n",
              "  ('fa', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('attach', 'RB'),\n",
              "  ('5', 'CD'),\n",
              "  ('case', 'NN'),\n",
              "  ('cite', 'JJ'),\n",
              "  ('headnote', 'NN')],\n",
              " [('1', 'CD'),\n",
              "  ('trial', 'NN'),\n",
              "  ('property', 'NN'),\n",
              "  ('statute', 'NN'),\n",
              "  ('november', 'NN'),\n",
              "  ('1840', 'CD'),\n",
              "  ('issued', 'VBD'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('sumter', 'NN'),\n",
              "  ('suit', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('error', 'NN'),\n",
              "  ('requiring', 'VBG'),\n",
              "  ('sheriff', 'JJ'),\n",
              "  ('county', 'NN'),\n",
              "  ('make', 'VBP'),\n",
              "  ('good', 'JJ'),\n",
              "  ('c', 'NN'),\n",
              "  ('allen', 'NNS'),\n",
              "  ('harrison', 'VBP'),\n",
              "  ('others', 'NNS'),\n",
              "  ('sum', 'VBD'),\n",
              "  ('thirtyseven', 'RB'),\n",
              "  ('hundred', 'VBN'),\n",
              "  ('seventyseven', 'RB'),\n",
              "  ('80100', 'CD'),\n",
              "  ('dollar', 'NN'),\n",
              "  ('besides', 'NNS'),\n",
              "  ('cost', 'NN'),\n",
              "  ('levied', 'VBD'),\n",
              "  ('thirty', 'JJ'),\n",
              "  ('bale', 'JJ'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('property', 'NN'),\n",
              "  ('allen', 'IN'),\n",
              "  ('harrison', 'NN'),\n",
              "  ('claimed', 'VBD'),\n",
              "  ('bond', 'NN'),\n",
              "  ('given', 'VBN'),\n",
              "  ('try', 'VB'),\n",
              "  ('issue', 'NN'),\n",
              "  ('made', 'VBN'),\n",
              "  ('try', 'JJ'),\n",
              "  ('question', 'NN'),\n",
              "  ('liability', 'NN'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('submitted', 'VBD'),\n",
              "  ('jury', 'NN'),\n",
              "  ('trial', 'NN'),\n",
              "  ('bill', 'NN'),\n",
              "  ('exception', 'NN'),\n",
              "  ('sealed', 'VBD'),\n",
              "  ('instance', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('proved', 'VBD'),\n",
              "  ('recovered', 'JJ'),\n",
              "  ('judgment', 'NN'),\n",
              "  ('october', 'NN'),\n",
              "  ('1839', 'CD'),\n",
              "  ('741', 'CD'),\n",
              "  ('issued', 'VBN'),\n",
              "  ('thereon', 'NN'),\n",
              "  ('7th', 'CD'),\n",
              "  ('nov', 'JJ'),\n",
              "  ('thereafter', 'RB'),\n",
              "  ('alias', 'JJ'),\n",
              "  ('pluries', 'NNS'),\n",
              "  ('fieri', 'VBP'),\n",
              "  ('facia', 'JJ'),\n",
              "  ('issued', 'VBN'),\n",
              "  ('regularly', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('made', 'VBN'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('levied', 'VBN'),\n",
              "  ('growed', 'VBN'),\n",
              "  ('plantation', 'NN'),\n",
              "  ('harrison', 'NN'),\n",
              "  ('cultivated', 'VBD'),\n",
              "  ('hand', 'NN'),\n",
              "  ('service', 'NN'),\n",
              "  ('proved', 'VBD'),\n",
              "  ('production', 'NN'),\n",
              "  ('written', 'VBN'),\n",
              "  ('harrison', 'JJ'),\n",
              "  ('twentysecond', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('1840', 'CD'),\n",
              "  ('consideration', 'NN'),\n",
              "  ('involved', 'VBN'),\n",
              "  ('indorser', 'RB'),\n",
              "  ('burton', 'NN'),\n",
              "  ('harrison', 'NN'),\n",
              "  ('sumter', 'NN'),\n",
              "  ('county', 'NN'),\n",
              "  ('exposed', 'VBD'),\n",
              "  ('amounting', 'JJ'),\n",
              "  ('upwards', 'NNS'),\n",
              "  ('fourteen', 'JJ'),\n",
              "  ('thousand', 'CD'),\n",
              "  ('dollar', 'NN'),\n",
              "  ('bargained', 'VBD'),\n",
              "  ('sold', 'VBN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('c', 'NN'),\n",
              "  ('consisting', 'VBG'),\n",
              "  ('one', 'CD'),\n",
              "  ('hundred', 'VBD'),\n",
              "  ('twenty', 'NN'),\n",
              "  ('acre', 'NN'),\n",
              "  ('c', 'NN'),\n",
              "  ('allen', 'IN'),\n",
              "  ('harrison', 'NN'),\n",
              "  ('promised', 'VBD'),\n",
              "  ('obliged', 'RB'),\n",
              "  ('give', 'JJ'),\n",
              "  ('use', 'NN'),\n",
              "  ('time', 'NN'),\n",
              "  ('save', 'VB'),\n",
              "  ('suffering', 'VBG'),\n",
              "  ('indorser', 'RB'),\n",
              "  ('matured', 'VBN'),\n",
              "  ('undertook', 'NN'),\n",
              "  ('deliver', 'NN'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('gainesville', 'NN'),\n",
              "  ('came', 'VBD'),\n",
              "  ('tennessee', 'NN'),\n",
              "  ('resided', 'VBD'),\n",
              "  ('first', 'JJ'),\n",
              "  ('september', 'NN'),\n",
              "  ('1840', 'CD'),\n",
              "  ('bringing', 'VBG'),\n",
              "  ('three', 'CD'),\n",
              "  ('four', 'CD'),\n",
              "  ('white', 'JJ'),\n",
              "  ('laborer', 'NN'),\n",
              "  ('took', 'VBD'),\n",
              "  ('possession', 'NN'),\n",
              "  ('slave', 'NN'),\n",
              "  ('latter', 'RBR'),\n",
              "  ('white', 'JJ'),\n",
              "  ('laborer', 'JJ'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('prepared', 'VBD'),\n",
              "  ('market', 'NN'),\n",
              "  ('levied', 'VBN'),\n",
              "  ('warehouse', 'IN'),\n",
              "  ('gainesville', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('proved', 'VBD'),\n",
              "  ('harrison', 'JJ'),\n",
              "  ('took', 'VBD'),\n",
              "  ('possession', 'NN'),\n",
              "  ('absent', 'NN'),\n",
              "  ('disposed', 'VBD'),\n",
              "  ('without', 'IN'),\n",
              "  ('consent', 'NN'),\n",
              "  ('admitted', 'VBN'),\n",
              "  ('made', 'VBD'),\n",
              "  ('good', 'JJ'),\n",
              "  ('faith', 'NN'),\n",
              "  ('charged', 'VBN'),\n",
              "  ('jury', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('virtue', 'NN'),\n",
              "  ('judgment', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('harrison', 'JJ'),\n",
              "  ('convey', 'NN'),\n",
              "  ('without', 'IN'),\n",
              "  ('manner', 'NN'),\n",
              "  ('restrained', 'VBD'),\n",
              "  ('writing', 'VBG'),\n",
              "  ('adduced', 'JJ'),\n",
              "  ('sale', 'NN'),\n",
              "  ('fieri', 'NN'),\n",
              "  ('facia', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('attached', 'VB'),\n",
              "  ('upon', 'IN'),\n",
              "  ('yet', 'RB'),\n",
              "  ('obtained', 'VBN'),\n",
              "  ('possession', 'NN'),\n",
              "  ('first', 'JJ'),\n",
              "  ('september', 'NN'),\n",
              "  ('controlled', 'VBN'),\n",
              "  ('gathering', 'NN'),\n",
              "  ('attached', 'VBN'),\n",
              "  ('subject', 'JJ'),\n",
              "  ('attorney', 'NN'),\n",
              "  ('law', 'NN'),\n",
              "  ('firm', 'NN'),\n",
              "  ('r', 'NN'),\n",
              "  ('h', 'NN'),\n",
              "  ('smith', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('error', 'NN'),\n",
              "  ('made', 'VBD'),\n",
              "  ('following', 'VBG'),\n",
              "  ('points1', 'JJ'),\n",
              "  ('harrison', 'NN'),\n",
              "  ('must', 'MD'),\n",
              "  ('may', 'MD'),\n",
              "  ('1840', 'VB'),\n",
              "  ('immature', 'NN'),\n",
              "  ('state', 'NN'),\n",
              "  ('insisted', 'VBD'),\n",
              "  ('subject', 'JJ'),\n",
              "  ('sale', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('common', 'JJ'),\n",
              "  ('law', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('could', 'MD'),\n",
              "  ('levied', 'VB'),\n",
              "  ('sold', 'VBD'),\n",
              "  ('1', 'CD'),\n",
              "  ('salk', 'NN'),\n",
              "  ('rep', 'VBD'),\n",
              "  ('361', 'CD'),\n",
              "  ('1', 'CD'),\n",
              "  ('bos', 'NNS'),\n",
              "  ('p', 'JJ'),\n",
              "  ('rep', 'VBP'),\n",
              "  ('307', 'CD'),\n",
              "  ('6', 'CD'),\n",
              "  ('east', 'JJ'),\n",
              "  ('rep', 'NN'),\n",
              "  ('604', 'CD'),\n",
              "  ('note', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('2', 'CD'),\n",
              "  ('john', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('418', 'CD'),\n",
              "  ('422', 'CD'),\n",
              "  ('7', 'CD'),\n",
              "  ('mass', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('34', 'CD'),\n",
              "  ('statue', 'NN'),\n",
              "  ('aik', 'NN'),\n",
              "  ('dig', 'NN'),\n",
              "  ('41', 'CD'),\n",
              "  ('p', 'NN'),\n",
              "  ('167', 'CD'),\n",
              "  ('forbids', 'NNS'),\n",
              "  ('742', 'CD'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('receive', 'JJ'),\n",
              "  ('strict', 'JJ'),\n",
              "  ('construction', 'NN'),\n",
              "  ('merely', 'RB'),\n",
              "  ('inhibits', 'VBZ'),\n",
              "  ('attache', 'JJ'),\n",
              "  ('sale', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('made', 'VB'),\n",
              "  ('matures', 'NNS'),\n",
              "  ('3', 'CD'),\n",
              "  ('purport', 'NN'),\n",
              "  ('convey', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('mere', 'JJ'),\n",
              "  ('executory', 'JJ'),\n",
              "  ('agreement', 'NN'),\n",
              "  ('requiring', 'VBG'),\n",
              "  ('act', 'NN'),\n",
              "  ('done', 'VBN'),\n",
              "  ('harrison', 'JJ'),\n",
              "  ('order', 'NN'),\n",
              "  ('invest', 'JJS'),\n",
              "  ('property', 'NN'),\n",
              "  ('chit', 'NN'),\n",
              "  ('con', 'VBD'),\n",
              "  ('112', 'CD'),\n",
              "  ('207', 'CD'),\n",
              "  ('3', 'CD'),\n",
              "  ('john', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('338', 'CD'),\n",
              "  ('424', 'CD'),\n",
              "  ('5', 'CD'),\n",
              "  ('wend', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('26', 'CD'),\n",
              "  ('13', 'CD'),\n",
              "  ('john', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('235', 'CD'),\n",
              "  ('8', 'CD'),\n",
              "  ('dowl', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('693', 'CD'),\n",
              "  ('act', 'NN'),\n",
              "  ('done', 'VBN'),\n",
              "  ('matter', 'RBR'),\n",
              "  ('liable', 'JJ'),\n",
              "  ('seized', 'VBN'),\n",
              "  ('harrison', 'JJ'),\n",
              "  ('debt', 'NN'),\n",
              "  ('chancery', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('compel', 'VB'),\n",
              "  ('specific', 'JJ'),\n",
              "  ('performance', 'NN'),\n",
              "  ('instance', 'NN'),\n",
              "  ('4', 'CD'),\n",
              "  ('charge', 'NN'),\n",
              "  ('also', 'RB'),\n",
              "  ('objectionable', 'JJ'),\n",
              "  ('deciding', 'VBG'),\n",
              "  ('disputed', 'VBN'),\n",
              "  ('fact', 'NN'),\n",
              "  ('w', 'NN'),\n",
              "  ('murphy', 'NN'),\n",
              "  ('w', 'NN'),\n",
              "  ('g', 'NN'),\n",
              "  ('jones', 'NNS'),\n",
              "  ('defendantcited', 'VBN'),\n",
              "  ('act', 'JJ'),\n",
              "  ('1821', 'CD'),\n",
              "  ('aik', 'JJ'),\n",
              "  ('dig', 'NN'),\n",
              "  ('167', 'CD'),\n",
              "  ('declares', 'NNS'),\n",
              "  ('lawful', 'JJ'),\n",
              "  ('planted', 'VBD'),\n",
              "  ('contended', 'JJ'),\n",
              "  ('attached', 'VBN'),\n",
              "  ('favor', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('restrained', 'VBD'),\n",
              "  ('making', 'VBG')],\n",
              " [('2', 'CD'),\n",
              "  ('destroyed', 'JJ'),\n",
              "  ('injunction', 'NN'),\n",
              "  ('take', 'VB'),\n",
              "  ('away', 'RP'),\n",
              "  ('short', 'JJ'),\n",
              "  ('whenever', 'WRB'),\n",
              "  ('temporarily', 'RB'),\n",
              "  ('suspended', 'VBN'),\n",
              "  ('withdrawn', 'NN'),\n",
              "  ('time', 'NN'),\n",
              "  ('lost', 'VBN'),\n",
              "  ('whipple', 'JJ'),\n",
              "  ('foot', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('john', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('216', 'CD'),\n",
              "  ('3', 'CD'),\n",
              "  ('wash', 'NN'),\n",
              "  ('c', 'NN'),\n",
              "  ('c', 'VBP'),\n",
              "  ('rep', 'VBZ'),\n",
              "  ('66', 'CD'),\n",
              "  ('4', 'CD'),\n",
              "  ('rep', 'NN'),\n",
              "  ('130', 'CD'),\n",
              "  ('admitted', 'VBN'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('good', 'JJ'),\n",
              "  ('faith', 'NN'),\n",
              "  ('severance', 'NN'),\n",
              "  ('removal', 'JJ'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('gave', 'VBD'),\n",
              "  ('latter', 'RBR'),\n",
              "  ('good', 'JJ'),\n",
              "  ('title', 'NN'),\n",
              "  ('creditor', 'NN'),\n",
              "  ('former', 'JJ'),\n",
              "  ('opinion', 'NN')],\n",
              " [('collier', 'JJR'), ('c', 'NNS'), ('j', 'NN')],\n",
              " [('doubt', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('existence', 'NN'),\n",
              "  ('subject', 'JJ'),\n",
              "  ('matter', 'NN'),\n",
              "  ('sale', 'NN'),\n",
              "  ('mortgage', 'NN'),\n",
              "  ('posse', 'JJ'),\n",
              "  ('interest', 'NN'),\n",
              "  ('vest', 'NN'),\n",
              "  ('possession', 'NN'),\n",
              "  ('either', 'CC'),\n",
              "  ('immediately', 'RB'),\n",
              "  ('future', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('proposition', 'NN'),\n",
              "  ('frequently', 'RB'),\n",
              "  ('assumed', 'VBD'),\n",
              "  ('unquestionable', 'JJ'),\n",
              "  ('point', 'NN'),\n",
              "  ('inquiry', 'NN'),\n",
              "  ('generally', 'RB'),\n",
              "  ('whether', 'IN'),\n",
              "  ('statute', 'NN'),\n",
              "  ('fraud', 'NN'),\n",
              "  ('29', 'CD'),\n",
              "  ('chas', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('mere', 'JJ'),\n",
              "  ('chattel', 'NN'),\n",
              "  ('transferrable', 'JJ'),\n",
              "  ('parol', 'NN'),\n",
              "  ('without', 'IN'),\n",
              "  ('writing', 'VBG'),\n",
              "  ('chitty', 'JJ'),\n",
              "  ('con', 'NN'),\n",
              "  ('2412', 'CD'),\n",
              "  ('332', 'CD'),\n",
              "  ('whipple', 'JJ'),\n",
              "  ('foot', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('john', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('422', 'CD'),\n",
              "  ('stewart', 'NN'),\n",
              "  ('doughty', 'NN'),\n",
              "  ('9', 'CD'),\n",
              "  ('john', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('112', 'CD'),\n",
              "  ('743', 'CD'),\n",
              "  ('austin', 'NN'),\n",
              "  ('sawyer', 'NN'),\n",
              "  ('9', 'CD'),\n",
              "  ('cow', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('39', 'CD'),\n",
              "  ('see', 'NN'),\n",
              "  ('also', 'RB'),\n",
              "  ('ravesies', 'VBZ'),\n",
              "  ('lee', 'VBZ'),\n",
              "  ('alston', 'IN'),\n",
              "  ('last', 'JJ'),\n",
              "  ('term', 'NN'),\n",
              "  ('set', 'VBD'),\n",
              "  ('bill', 'NN'),\n",
              "  ('exception', 'NN'),\n",
              "  ('inclined', 'VBD'),\n",
              "  ('think', 'VBP'),\n",
              "  ('evidence', 'NN'),\n",
              "  ('rather', 'RB'),\n",
              "  ('mortgage', 'NN'),\n",
              "  ('absolute', 'JJ'),\n",
              "  ('sale', 'NN'),\n",
              "  ('recites', 'NNS'),\n",
              "  ('involved', 'VBD'),\n",
              "  ('indorser', 'RB'),\n",
              "  ('mercantile', 'JJ'),\n",
              "  ('firm', 'NN'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('partner', 'NN'),\n",
              "  ('upwards', 'NNS'),\n",
              "  ('fourteen', 'JJ'),\n",
              "  ('thousand', 'CD'),\n",
              "  ('dollar', 'NN'),\n",
              "  ('estate', 'NN'),\n",
              "  ('sheriff', 'JJ'),\n",
              "  ('hand', 'NN'),\n",
              "  ('conveyance', 'NN'),\n",
              "  ('made', 'VBD'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('corn', 'NN'),\n",
              "  ('oat', 'NN'),\n",
              "  ('grantor', 'NN'),\n",
              "  ('agrees', 'VBZ'),\n",
              "  ('give', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('use', 'NN'),\n",
              "  ('prevent', 'JJ'),\n",
              "  ('injury', 'NN'),\n",
              "  ('indorser', 'NN'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('might', 'MD'),\n",
              "  ('time', 'NN'),\n",
              "  ('divested', 'VBN'),\n",
              "  ('interest', 'NN'),\n",
              "  ('vested', 'VBN'),\n",
              "  ('discharging', 'VBG'),\n",
              "  ('liability', 'NN'),\n",
              "  ('indorser', 'NN'),\n",
              "  ('judgment', 'NN'),\n",
              "  ('creditor', 'NN'),\n",
              "  ('might', 'MD'),\n",
              "  ('satisfied', 'VB'),\n",
              "  ('levied', 'JJ'),\n",
              "  ('sold', 'VBN'),\n",
              "  ('fieri', 'NN'),\n",
              "  ('facia', 'JJ'),\n",
              "  ('consider', 'NN'),\n",
              "  ('writing', 'VBG'),\n",
              "  ('assert', 'JJ'),\n",
              "  ('mortgage', 'NN'),\n",
              "  ('power', 'NN'),\n",
              "  ('take', 'VB'),\n",
              "  ('possession', 'NN'),\n",
              "  ('time', 'NN'),\n",
              "  ('year', 'NN'),\n",
              "  ('unless', 'IN'),\n",
              "  ('relieved', 'VBN'),\n",
              "  ('engagement', 'NN'),\n",
              "  ('indorser', 'NN'),\n",
              "  ('pretended', 'VBD'),\n",
              "  ('liability', 'NN'),\n",
              "  ('satisfied', 'VBN'),\n",
              "  ('admitted', 'VBN'),\n",
              "  ('party', 'NN'),\n",
              "  ('acted', 'VBD'),\n",
              "  ('good', 'JJ'),\n",
              "  ('faith', 'NN'),\n",
              "  ('dry', 'JJ'),\n",
              "  ('question', 'NN'),\n",
              "  ('law', 'NN'),\n",
              "  ('whether', 'IN'),\n",
              "  ('plaintiff', 'JJ'),\n",
              "  ('shall', 'MD'),\n",
              "  ('prevail', 'VB'),\n",
              "  ('assuming', 'VBG'),\n",
              "  ('present', 'JJ'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('operate', 'NN'),\n",
              "  ('upon', 'IN'),\n",
              "  ('planted', 'VBN'),\n",
              "  ('previous', 'JJ'),\n",
              "  ('may', 'MD'),\n",
              "  ('1840', 'CD'),\n",
              "  ('inquire', 'VB'),\n",
              "  ('whether', 'IN'),\n",
              "  ('defendant', 'JJ'),\n",
              "  ('interest', 'NN'),\n",
              "  ('could', 'MD'),\n",
              "  ('levied', 'VB'),\n",
              "  ('sold', 'VBN'),\n",
              "  ('previous', 'JJ'),\n",
              "  ('taken', 'VBN'),\n",
              "  ('possession', 'NN'),\n",
              "  ('prepared', 'JJ'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('market', 'NN'),\n",
              "  ('removed', 'VBD'),\n",
              "  ('warehouse', 'WP'),\n",
              "  ('possession', 'NN'),\n",
              "  ('insisted', 'VBD'),\n",
              "  ('trespass', 'NN'),\n",
              "  ('acquired', 'VBD'),\n",
              "  ('absence', 'NN'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('without', 'IN'),\n",
              "  ('consent', 'NN'),\n",
              "  ('given', 'VBN'),\n",
              "  ('conceding', 'VBG'),\n",
              "  ('truth', 'NN'),\n",
              "  ('fact', 'NN'),\n",
              "  ('stated', 'VBN'),\n",
              "  ('bill', 'NN'),\n",
              "  ('exception', 'NN'),\n",
              "  ('think', 'VBP'),\n",
              "  ('follow', 'JJ'),\n",
              "  ('possession', 'NN'),\n",
              "  ('nullity', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('must', 'MD'),\n",
              "  ('considered', 'VBN'),\n",
              "  ('never', 'RB'),\n",
              "  ('interfered', 'VBN'),\n",
              "  ('contains', 'NNS'),\n",
              "  ('express', 'RBR'),\n",
              "  ('undertaking', 'VBG'),\n",
              "  ('give', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('might', 'MD'),\n",
              "  ('require', 'VB'),\n",
              "  ('indemnity', 'NN'),\n",
              "  ('took', 'VBD'),\n",
              "  ('possession', 'NN'),\n",
              "  ('absence', 'NN'),\n",
              "  ('grantor', 'NN'),\n",
              "  ('though', 'IN'),\n",
              "  ('without', 'IN'),\n",
              "  ('consent', 'NN'),\n",
              "  ('subsequently', 'RB'),\n",
              "  ('acquiesced', 'VBD'),\n",
              "  ('inference', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('necessary', 'JJ'),\n",
              "  ('act', 'NN'),\n",
              "  ('approved', 'VBD'),\n",
              "  ('taking', 'VBG'),\n",
              "  ('clear', 'JJ'),\n",
              "  ('744', 'CD'),\n",
              "  ('law', 'NN'),\n",
              "  ('seen', 'VBN'),\n",
              "  ('defendant', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('nothing', 'NN'),\n",
              "  ('mere', 'RB'),\n",
              "  ('equitable', 'JJ'),\n",
              "  ('redeem', 'VBP'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('paying', 'VBG'),\n",
              "  ('debt', 'NN'),\n",
              "  ('indorsed', 'VBN'),\n",
              "  ('possession', 'NN'),\n",
              "  ('coupled', 'VBN'),\n",
              "  ('equity', 'NN'),\n",
              "  ('naked', 'JJ'),\n",
              "  ('equity', 'NN'),\n",
              "  ('held', 'VBD'),\n",
              "  ('can', 'MD'),\n",
              "  ('not', 'RB'),\n",
              "  ('reached', 'VB'),\n",
              "  ('ordinary', 'JJ'),\n",
              "  ('perkins', 'NNS'),\n",
              "  ('elliott', 'VBP'),\n",
              "  ('mayfield', '$'),\n",
              "  ('5', 'CD'),\n",
              "  ('porter', 'NN'),\n",
              "  ('rep', 'NN'),\n",
              "  ('182', 'CD')],\n",
              " [('3', 'CD'),\n",
              "  ('brings', 'NNS'),\n",
              "  ('u', 'JJ'),\n",
              "  ('back', 'RB'),\n",
              "  ('question', 'NN'),\n",
              "  ('whether', 'IN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('defeat', 'JJ'),\n",
              "  ('mortgage', 'NN'),\n",
              "  ('frequently', 'RB'),\n",
              "  ('mooted', 'VBD'),\n",
              "  ('whether', 'IN'),\n",
              "  ('common', 'JJ'),\n",
              "  ('law', 'NN'),\n",
              "  ('corn', 'NN'),\n",
              "  ('c', 'NNS'),\n",
              "  ('seized', 'VBD'),\n",
              "  ('fieri', 'JJ'),\n",
              "  ('facia', 'NN'),\n",
              "  ('mr', 'NN'),\n",
              "  ('dane', 'NN'),\n",
              "  ('remarking', 'VBG'),\n",
              "  ('upon', 'IN'),\n",
              "  ('point', 'NN'),\n",
              "  ('say', 'VBP'),\n",
              "  ('american', 'JJ'),\n",
              "  ('editor', 'NN'),\n",
              "  ('bacon', 'NN'),\n",
              "  ('abridgment', 'NN'),\n",
              "  ('say', 'VBP'),\n",
              "  ('wheat', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('ground', 'NN'),\n",
              "  ('chattel', 'NN'),\n",
              "  ('subject', 'NN'),\n",
              "  ('taken', 'VBN'),\n",
              "  ('sheriff', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('suffer', 'VB'),\n",
              "  ('grow', 'VB'),\n",
              "  ('till', 'NN'),\n",
              "  ('harvest', 'JJS'),\n",
              "  ('cut', 'NN'),\n",
              "  ('sell', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('perhaps', 'RB'),\n",
              "  ('sell', 'VB'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('purchaser', 'RB'),\n",
              "  ('entitled', 'VBN'),\n",
              "  ('enter', 'NN'),\n",
              "  ('purpose', 'NN'),\n",
              "  ('cutting', 'VBG'),\n",
              "  ('carrying', 'VBG'),\n",
              "  ('away', 'RB'),\n",
              "  ('cite', 'JJ'),\n",
              "  ('whipple', 'JJ'),\n",
              "  ('foot', 'NN'),\n",
              "  ('ut', 'JJ'),\n",
              "  ('supra', 'NN'),\n",
              "  ('also', 'RB'),\n",
              "  ('pooles', 'VBZ'),\n",
              "  ('case', 'NN'),\n",
              "  ('salk', 'VBD'),\n",
              "  ('368', 'CD'),\n",
              "  ('1', 'CD'),\n",
              "  ('bos', 'NNS'),\n",
              "  ('p', 'VBD'),\n",
              "  ('397', 'CD'),\n",
              "  ('6', 'CD'),\n",
              "  ('east', 'JJ'),\n",
              "  ('604', 'CD'),\n",
              "  ('n', 'JJ'),\n",
              "  ('whipple', 'JJ'),\n",
              "  ('foot', 'NN'),\n",
              "  ('seems', 'VBZ'),\n",
              "  ('case', 'NN'),\n",
              "  ('support', 'NN'),\n",
              "  ('position', 'NN'),\n",
              "  ('unripe', 'JJ'),\n",
              "  ('wheat', 'NN'),\n",
              "  ('corn', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('taken', 'VBN'),\n",
              "  ('editor', 'NN'),\n",
              "  ('state', 'NN'),\n",
              "  ('nothing', 'NN'),\n",
              "  ('taken', 'VBN'),\n",
              "  ('can', 'MD'),\n",
              "  ('not', 'RB'),\n",
              "  ('sold', 'VB'),\n",
              "  ('position', 'NN'),\n",
              "  ('say', 'VBP'),\n",
              "  ('learned', 'VBN'),\n",
              "  ('commentator', 'NN'),\n",
              "  ('doubt', 'NN'),\n",
              "  ('law', 'NN'),\n",
              "  ('unnecessary', 'JJ'),\n",
              "  ('consider', 'VBP'),\n",
              "  ('matter', 'NN'),\n",
              "  ('stand', 'NN'),\n",
              "  ('common', 'JJ'),\n",
              "  ('law', 'NN'),\n",
              "  ('first', 'JJ'),\n",
              "  ('section', 'NN'),\n",
              "  ('act', 'NN'),\n",
              "  ('1821', 'CD'),\n",
              "  ('prevent', 'NN'),\n",
              "  ('sheriff', 'JJ'),\n",
              "  ('officer', 'NN'),\n",
              "  ('levying', 'VBG'),\n",
              "  ('certain', 'JJ'),\n",
              "  ('case', 'NN'),\n",
              "  ('enacts', 'VBZ'),\n",
              "  ('shall', 'MD'),\n",
              "  ('lawful', 'JJ'),\n",
              "  ('sheriff', 'JJ'),\n",
              "  ('officer', 'NN'),\n",
              "  ('writ', 'NN'),\n",
              "  ('fieri', 'NN'),\n",
              "  ('facia', 'NN'),\n",
              "  ('planted', 'VBD'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('person', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('issue', 'VB'),\n",
              "  ('aik', 'VB'),\n",
              "  ('dig', 'JJ'),\n",
              "  ('167', 'CD'),\n",
              "  ('express', 'JJ'),\n",
              "  ('inhibition', 'NN'),\n",
              "  ('remains', 'VBZ'),\n",
              "  ('ground', 'NN'),\n",
              "  ('severed', 'VBD'),\n",
              "  ('soil', 'NN'),\n",
              "  ('owes', 'NN'),\n",
              "  ('growth', 'NN'),\n",
              "  ('respect', 'VBP'),\n",
              "  ('property', 'NN'),\n",
              "  ('thus', 'RB'),\n",
              "  ('situated', 'VBD'),\n",
              "  ('attach', 'JJ'),\n",
              "  ('eo', 'NN'),\n",
              "  ('instanti', 'NN'),\n",
              "  ('upon', 'IN'),\n",
              "  ('placed', 'JJ'),\n",
              "  ('hand', 'NN'),\n",
              "  ('officer', 'NN'),\n",
              "  ('act', 'NN'),\n",
              "  ('cited', 'VBD'),\n",
              "  ('effect', 'NN'),\n",
              "  ('keeping', 'VBG'),\n",
              "  ('abeyance', 'NN'),\n",
              "  ('operate', 'NN'),\n",
              "  ('prevent', 'NN'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('disposing', 'VBG'),\n",
              "  ('property', 'NN'),\n",
              "  ('attache', 'NN'),\n",
              "  ('give', 'VBP'),\n",
              "  ('creditor', 'NN'),\n",
              "  ('sold', 'VBD'),\n",
              "  ('satisfy', 'RB'),\n",
              "  ('745', 'CD'),\n",
              "  ('judgment', 'NN'),\n",
              "  ('intimately', 'RB'),\n",
              "  ('connected', 'VBN'),\n",
              "  ('latter', 'NN'),\n",
              "  ('taken', 'VBN'),\n",
              "  ('away', 'RB'),\n",
              "  ('suspended', 'JJ'),\n",
              "  ('effect', 'NN'),\n",
              "  ('common', 'JJ'),\n",
              "  ('law', 'NN'),\n",
              "  ('destruction', 'NN'),\n",
              "  ('former', 'JJ'),\n",
              "  ('principle', 'NN'),\n",
              "  ('fully', 'RB'),\n",
              "  ('established', 'VBN'),\n",
              "  ('mansony', 'NN'),\n",
              "  ('hurtell', 'NN'),\n",
              "  ('president', 'NN'),\n",
              "  ('c', 'VBD'),\n",
              "  ('bank', 'NN'),\n",
              "  ('united', 'JJ'),\n",
              "  ('state', 'NN'),\n",
              "  ('assignee', 'NN'),\n",
              "  ('citation', 'NN'),\n",
              "  ('contained', 'VBN'),\n",
              "  ('opinion', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('also', 'RB'),\n",
              "  ('opinion', 'NN'),\n",
              "  ('wood', 'NN'),\n",
              "  ('gary', 'JJ'),\n",
              "  ('et', 'NN'),\n",
              "  ('al', 'NN'),\n",
              "  ('decided', 'VBD'),\n",
              "  ('last', 'JJ'),\n",
              "  ('term', 'NN'),\n",
              "  ('competent', 'NN'),\n",
              "  ('legislature', 'NN'),\n",
              "  ('made', 'VBD'),\n",
              "  ('unlawful', 'JJ'),\n",
              "  ('particular', 'JJ'),\n",
              "  ('property', 'NN'),\n",
              "  ('condition', 'NN'),\n",
              "  ('changed', 'VBD'),\n",
              "  ('still', 'RB'),\n",
              "  ('give', 'VB'),\n",
              "  ('continuing', 'VBG'),\n",
              "  ('can', 'MD'),\n",
              "  ('not', 'RB'),\n",
              "  ('doubted', 'VB'),\n",
              "  ('nothing', 'NN'),\n",
              "  ('act', 'JJ'),\n",
              "  ('question', 'NN'),\n",
              "  ('indicate', 'VBP'),\n",
              "  ('intention', 'NN'),\n",
              "  ('object', 'VBP'),\n",
              "  ('merely', 'RB'),\n",
              "  ('suspend', 'JJ'),\n",
              "  ('sale', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('easy', 'VB'),\n",
              "  ('said', 'VBD'),\n",
              "  ('explicit', 'JJ'),\n",
              "  ('term', 'NN'),\n",
              "  ('declaring', 'VBG'),\n",
              "  ('statute', 'JJ'),\n",
              "  ('totidem', 'NN'),\n",
              "  ('verbis', 'NN'),\n",
              "  ('shall', 'MD'),\n",
              "  ('levied', 'JJ'),\n",
              "  ('legislature', 'NN'),\n",
              "  ('must', 'MD'),\n",
              "  ('supposed', 'VBN'),\n",
              "  ('meant', 'VB'),\n",
              "  ('expressed', 'VBN'),\n",
              "  ('act', 'NN'),\n",
              "  ('induced', 'VBD'),\n",
              "  ('doubt', 'NN'),\n",
              "  ('existed', 'VBD'),\n",
              "  ('common', 'JJ'),\n",
              "  ('law', 'NN'),\n",
              "  ('intended', 'VBN'),\n",
              "  ('remove', 'VB'),\n",
              "  ('doubt', 'NN'),\n",
              "  ('declaring', 'VBG'),\n",
              "  ('law', 'NN'),\n",
              "  ('future', 'NN'),\n",
              "  ('create', 'VBP'),\n",
              "  ('authorize', 'VB'),\n",
              "  ('case', 'NN'),\n",
              "  ('law', 'NN'),\n",
              "  ('existed', 'VBD'),\n",
              "  ('silent', 'JJ'),\n",
              "  ('idea', 'NN'),\n",
              "  ('attached', 'VBN'),\n",
              "  ('upon', 'IN'),\n",
              "  ('planted', 'VBN'),\n",
              "  ('soon', 'RB'),\n",
              "  ('delivered', 'JJ'),\n",
              "  ('sheriff', 'NN'),\n",
              "  ('though', 'IN'),\n",
              "  ('postponed', 'JJ'),\n",
              "  ('severance', 'NN'),\n",
              "  ('took', 'VBD'),\n",
              "  ('place', 'NN'),\n",
              "  ('attempted', 'VBN'),\n",
              "  ('deduced', 'VBN'),\n",
              "  ('last', 'JJ'),\n",
              "  ('word', 'NN'),\n",
              "  ('section', 'NN'),\n",
              "  ('cited', 'VBD'),\n",
              "  ('viz', 'JJ'),\n",
              "  ('word', 'NN'),\n",
              "  ('can', 'MD'),\n",
              "  ('not', 'RB'),\n",
              "  ('upon', 'VB'),\n",
              "  ('principle', 'NN'),\n",
              "  ('construction', 'NN'),\n",
              "  ('regarded', 'VBD'),\n",
              "  ('potent', 'JJ'),\n",
              "  ('give', 'JJ'),\n",
              "  ('retrospective', 'JJ'),\n",
              "  ('effect', 'NN'),\n",
              "  ('refer', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('postpone', 'VB'),\n",
              "  ('relate', 'VB'),\n",
              "  ('postpone', 'JJ'),\n",
              "  ('event', 'NN'),\n",
              "  ('take', 'VB'),\n",
              "  ('place', 'NN')],\n",
              " [('4', 'CD'),\n",
              "  ('planted', 'VBD'),\n",
              "  ('expressly', 'RB'),\n",
              "  ('taken', 'VBN'),\n",
              "  ('away', 'RP'),\n",
              "  ('statute', 'JJ'),\n",
              "  ('connected', 'JJ'),\n",
              "  ('consequent', 'NN'),\n",
              "  ('upon', 'IN'),\n",
              "  ('never', 'RB'),\n",
              "  ('attache', 'VBN'),\n",
              "  ('severance', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('defendant', 'JJ'),\n",
              "  ('make', 'NN'),\n",
              "  ('unquestionable', 'JJ'),\n",
              "  ('title', 'NN'),\n",
              "  ('coupled', 'VBD'),\n",
              "  ('possession', 'NN'),\n",
              "  ('paramount', 'NN'),\n",
              "  ('could', 'MD'),\n",
              "  ('exert', 'VB'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('judge', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('mistaken', 'VB'),\n",
              "  ('law', 'NN'),\n",
              "  ('supposing', 'VBG'),\n",
              "  ('sale', 'NN'),\n",
              "  ('error', 'NN'),\n",
              "  ('respect', 'VBP'),\n",
              "  ('immaterial', 'JJ'),\n",
              "  ('whether', 'IN'),\n",
              "  ('sale', 'NN'),\n",
              "  ('mortgage', 'NN'),\n",
              "  ('746', 'CD'),\n",
              "  ('seen', 'VBN'),\n",
              "  ('fact', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('defendant', 'JJ'),\n",
              "  ('interest', 'NN'),\n",
              "  ('could', 'MD'),\n",
              "  ('seised', 'VBN'),\n",
              "  ('sold', 'VBN'),\n",
              "  ('assumption', 'NN'),\n",
              "  ('material', 'NN'),\n",
              "  ('fact', 'NN'),\n",
              "  ('charge', 'NN'),\n",
              "  ('possession', 'NN'),\n",
              "  ('time', 'NN'),\n",
              "  ('acquired', 'VBD'),\n",
              "  ('gathering', 'VBG'),\n",
              "  ('c', 'NN'),\n",
              "  ('referred', 'VBD'),\n",
              "  ('determination', 'JJ'),\n",
              "  ('jury', 'NN'),\n",
              "  ('instructed', 'VBD'),\n",
              "  ('find', 'IN'),\n",
              "  ('according', 'VBG'),\n",
              "  ('evidence', 'NN'),\n",
              "  ('adduced', 'VBD'),\n",
              "  ('ever', 'RB'),\n",
              "  ('attached', 'VBN'),\n",
              "  ('favor', 'NN'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('bona', 'NN'),\n",
              "  ('fides', 'NNS'),\n",
              "  ('conceded', 'VBD'),\n",
              "  ('charge', 'NN'),\n",
              "  ('necessary', 'JJ'),\n",
              "  ('point', 'NN'),\n",
              "  ('could', 'MD'),\n",
              "  ('propriety', 'VB'),\n",
              "  ('enter', 'RB'),\n",
              "  ('inquiry', 'JJ'),\n",
              "  ('jury', 'NN'),\n",
              "  ('result', 'NN'),\n",
              "  ('said', 'VBD'),\n",
              "  ('judgment', 'NN'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('affirmed', 'VBD')],\n",
              " [('dissenting', 'VBG'), ('opinion', 'NN')],\n",
              " [('ormond', 'NN'), ('j', 'NN')],\n",
              " [('4', 'CD'),\n",
              "  ('statute', 'JJ'),\n",
              "  ('present', 'JJ'),\n",
              "  ('question', 'NN'),\n",
              "  ('shall', 'MD'),\n",
              "  ('lawful', 'VB'),\n",
              "  ('sheriff', 'JJ'),\n",
              "  ('officer', 'NN'),\n",
              "  ('writ', 'NN'),\n",
              "  ('fieei', 'NN'),\n",
              "  ('facia', 'NN'),\n",
              "  ('planted', 'VBD'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('person', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('issue', 'VB'),\n",
              "  ('clay', 'VB'),\n",
              "  ('dig', 'JJ'),\n",
              "  ('210', 'CD'),\n",
              "  ('46', 'CD'),\n",
              "  ('shall', 'MD'),\n",
              "  ('enter', 'VB'),\n",
              "  ('upon', 'IN'),\n",
              "  ('enquiry', 'NN'),\n",
              "  ('whether', 'IN'),\n",
              "  ('common', 'JJ'),\n",
              "  ('law', 'NN'),\n",
              "  ('could', 'MD'),\n",
              "  ('levied', 'VB'),\n",
              "  ('upon', 'IN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('though', 'IN'),\n",
              "  ('apprehend', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('difficult', 'JJ'),\n",
              "  ('maintain', 'VB'),\n",
              "  ('affirmative', 'JJ'),\n",
              "  ('proposition', 'NN'),\n",
              "  ('sufficient', 'JJ'),\n",
              "  ('purpose', 'NN'),\n",
              "  ('statute', 'NN'),\n",
              "  ('supposes', 'VBZ'),\n",
              "  ('law', 'NN'),\n",
              "  ('doubtless', 'NN'),\n",
              "  ('practice', 'NN'),\n",
              "  ('act', 'NN'),\n",
              "  ('must', 'MD'),\n",
              "  ('considered', 'VBN'),\n",
              "  ('connection', 'NN'),\n",
              "  ('act', 'NN'),\n",
              "  ('upon', 'IN'),\n",
              "  ('subject', 'JJ'),\n",
              "  ('policy', 'NN'),\n",
              "  ('state', 'NN'),\n",
              "  ('indicated', 'VBD'),\n",
              "  ('statute', 'NN'),\n",
              "  ('undeniably', 'RB'),\n",
              "  ('property', 'NN'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('real', 'JJ'),\n",
              "  ('personal', 'JJ'),\n",
              "  ('legal', 'JJ'),\n",
              "  ('title', 'NN'),\n",
              "  ('shall', 'MD'),\n",
              "  ('subject', 'VB'),\n",
              "  ('sale', 'NN'),\n",
              "  ('appears', 'VBZ'),\n",
              "  ('would', 'MD'),\n",
              "  ('difficult', 'JJ'),\n",
              "  ('assign', 'VB'),\n",
              "  ('reason', 'NN'),\n",
              "  ('exemption', 'NN'),\n",
              "  ('specie', 'NN'),\n",
              "  ('property', 'NN'),\n",
              "  ('claim', 'NN'),\n",
              "  ('judgment', 'NN'),\n",
              "  ('creditor', 'NN'),\n",
              "  ('giving', 'VBG'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('dispose', 'JJ'),\n",
              "  ('appears', 'VBZ'),\n",
              "  ('deference', 'NN'),\n",
              "  ('argument', 'NN'),\n",
              "  ('sheriff', 'NN'),\n",
              "  ('prohibited', 'VBD'),\n",
              "  ('levying', 'VBG'),\n",
              "  ('planted', 'VBN'),\n",
              "  ('therefore', 'RB'),\n",
              "  ('lost', 'VBN'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('sell', 'NN'),\n",
              "  ('non', 'RB'),\n",
              "  ('sequitur', 'JJ'),\n",
              "  ('mischief', 'NN'),\n",
              "  ('statute', 'NN'),\n",
              "  ('designed', 'VBN'),\n",
              "  ('remedy', 'NN'),\n",
              "  ('sacrifice', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('necessarily', 'RB'),\n",
              "  ('made', 'VB'),\n",
              "  ('sale', 'NN'),\n",
              "  ('immature', 'NN'),\n",
              "  ('statute', 'NN'),\n",
              "  ('enables', 'VBZ'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('retain', 'NN'),\n",
              "  ('matures', 'VBZ'),\n",
              "  ('severing', 'VBG'),\n",
              "  ('soil', 'NN'),\n",
              "  ('put', 'VBD'),\n",
              "  ('747', 'CD'),\n",
              "  ('condition', 'NN'),\n",
              "  ('bring', 'VBG'),\n",
              "  ('valuethe', 'JJ'),\n",
              "  ('mean', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('continuing', 'VBG'),\n",
              "  ('plaintiff', 'NN')],\n",
              " [('5', 'CD'),\n",
              "  ('confirmation', 'NN'),\n",
              "  ('correctness', 'NN'),\n",
              "  ('view', 'NN'),\n",
              "  ('necessary', 'JJ'),\n",
              "  ('found', 'VBD'),\n",
              "  ('think', 'JJ'),\n",
              "  ('language', 'NN'),\n",
              "  ('employed', 'VBN'),\n",
              "  ('legislature', 'NN'),\n",
              "  ('sheriff', 'NN'),\n",
              "  ('forbidden', 'NN'),\n",
              "  ('planted', 'VBN'),\n",
              "  ('view', 'NN'),\n",
              "  ('taken', 'VBN'),\n",
              "  ('majority', 'NN'),\n",
              "  ('correct', 'NN'),\n",
              "  ('secured', 'VBN'),\n",
              "  ('plaintiff', 'IN'),\n",
              "  ('levying', 'VBG'),\n",
              "  ('may', 'MD'),\n",
              "  ('frustrated', 'VB'),\n",
              "  ('case', 'NN'),\n",
              "  ('sale', 'NN'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('whilst', 'JJ'),\n",
              "  ('immature', 'NN'),\n",
              "  ('state', 'NN'),\n",
              "  ('construction', 'NN'),\n",
              "  ('put', 'VBD'),\n",
              "  ('upon', 'IN'),\n",
              "  ('statute', 'NN'),\n",
              "  ('involves', 'VBZ'),\n",
              "  ('singular', 'JJ'),\n",
              "  ('anomaly', 'JJ'),\n",
              "  ('legislature', 'NN'),\n",
              "  ('protection', 'NN'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('forbidden', 'JJ'),\n",
              "  ('plaintiff', 'NN'),\n",
              "  ('sell', 'VBP'),\n",
              "  ('property', 'NN'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('condition', 'NN'),\n",
              "  ('bring', 'VBG'),\n",
              "  ('value', 'NN'),\n",
              "  ('yet', 'RB'),\n",
              "  ('permit', 'JJ'),\n",
              "  ('debtor', 'NN'),\n",
              "  ('voluntarily', 'RB'),\n",
              "  ('sale', 'NN'),\n",
              "  ('submit', 'NN'),\n",
              "  ('sacrifice', 'NN'),\n",
              "  ('benefit', 'NN'),\n",
              "  ('effect', 'NN'),\n",
              "  ('gift', 'NN'),\n",
              "  ('defendant', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('provided', 'VBD'),\n",
              "  ('gather', 'NN'),\n",
              "  ('disposes', 'NNS'),\n",
              "  ('condition', 'NN'),\n",
              "  ('feel', 'VBP'),\n",
              "  ('thorough', 'IN'),\n",
              "  ('conviction', 'NN'),\n",
              "  ('intention', 'NN'),\n",
              "  ('legislature', 'NN'),\n",
              "  ('secure', 'NN'),\n",
              "  ('loss', 'NN'),\n",
              "  ('prohibiting', 'VBG'),\n",
              "  ('sale', 'NN'),\n",
              "  ('temporary', 'JJ'),\n",
              "  ('suspension', 'NN'),\n",
              "  ('sell', 'NN'),\n",
              "  ('ceased', 'VBD'),\n",
              "  ('citation', 'NN'),\n",
              "  ('5', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('740', 'CD'),\n",
              "  ('1843', 'CD'),\n",
              "  ('wl', 'NN'),\n",
              "  ('284', 'CD'),\n",
              "  ('end', 'NN'),\n",
              "  ('document', 'NN'),\n",
              "  ('2019', 'CD'),\n",
              "  ('thomson', 'NN'),\n",
              "  ('reuters', 'NNS'),\n",
              "  ('claim', 'VBP'),\n",
              "  ('original', 'JJ'),\n",
              "  ('u', 'JJ'),\n",
              "  ('government', 'NN'),\n",
              "  ('work', 'NN')],\n",
              " [('citing', 'VBG'),\n",
              "  ('reference', 'NN'),\n",
              "  ('9', 'CD'),\n",
              "  ('treatment', 'NN'),\n",
              "  ('title', 'NN'),\n",
              "  ('date', 'NN'),\n",
              "  ('type', 'NN'),\n",
              "  ('depth', 'NN'),\n",
              "  ('headnotes', 'NNS')],\n",
              " [('cited', 'VBD'),\n",
              "  ('1', 'CD'),\n",
              "  ('booker', 'NN'),\n",
              "  ('jones', 'NNS'),\n",
              "  ('admx', 'RB'),\n",
              "  ('55', 'CD'),\n",
              "  ('ala', 'JJ'),\n",
              "  ('266', 'CD'),\n",
              "  ('271', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('trover', 'NN'),\n",
              "  ('conversion', 'NN'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('count', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('appeal', 'NN'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('hale', 'NN'),\n",
              "  ('tried', 'VBD'),\n",
              "  ('hon', 'JJ'),\n",
              "  ('j', 'NN'),\n",
              "  ('saffold', 'VBD'),\n",
              "  ('dec', 'JJ'),\n",
              "  ('term', 'NN'),\n",
              "  ('1876', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('cited', 'VBD'),\n",
              "  ('2', 'CD'),\n",
              "  ('lehman', 'NN'),\n",
              "  ('durr', 'NN'),\n",
              "  ('co', 'NN'),\n",
              "  ('marshall', 'NN'),\n",
              "  ('47', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('362', 'CD'),\n",
              "  ('376', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('trover', 'NN'),\n",
              "  ('conversion', 'NN'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('appeal', 'NN'),\n",
              "  ('city', 'NN'),\n",
              "  ('montgomery', 'NN'),\n",
              "  ('tried', 'VBD'),\n",
              "  ('hon', 'JJ'),\n",
              "  ('john', 'NN'),\n",
              "  ('cunningham', 'NN'),\n",
              "  ('jan', 'NN'),\n",
              "  ('term', 'NN'),\n",
              "  ('1872', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('cited', 'VBD'),\n",
              "  ('3', 'CD'),\n",
              "  ('bibb', 'NN'),\n",
              "  ('janney', 'NN'),\n",
              "  ('45', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('329', 'CD'),\n",
              "  ('334', 'CD'),\n",
              "  ('ala', 'JJ'),\n",
              "  ('garnishment', 'NN'),\n",
              "  ('wage', 'NN'),\n",
              "  ('waiver', 'WRB'),\n",
              "  ('exemption', 'NN'),\n",
              "  ('appeal', 'NN'),\n",
              "  ('city', 'NN'),\n",
              "  ('montgomery', 'NN'),\n",
              "  ('tried', 'VBD'),\n",
              "  ('hon', 'JJ'),\n",
              "  ('john', 'NN'),\n",
              "  ('cunningham', 'NN'),\n",
              "  ('jan', 'NN'),\n",
              "  ('term', 'NN'),\n",
              "  ('1871', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('cited', 'VBD'),\n",
              "  ('4', 'CD'),\n",
              "  ('mckenzie', 'NN'),\n",
              "  ('lampley', 'NN'),\n",
              "  ('31', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('526', 'CD'),\n",
              "  ('527', 'CD'),\n",
              "  ('ala', 'JJ'),\n",
              "  ('trial', 'NN'),\n",
              "  ('property', 'NN'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('appeal', 'NN'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('barbour', 'NN'),\n",
              "  ('tried', 'VBD'),\n",
              "  ('hon', 'JJ'),\n",
              "  ('hale', 'JJ'),\n",
              "  ('jan', 'NN'),\n",
              "  ('term', 'NN'),\n",
              "  ('1858', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('cited', 'VBD'),\n",
              "  ('5', 'CD'),\n",
              "  ('evans', 'NNS'),\n",
              "  ('lamar', 'VBP'),\n",
              "  ('21', 'CD'),\n",
              "  ('ala', 'JJ'),\n",
              "  ('333', 'CD'),\n",
              "  ('335', 'CD'),\n",
              "  ('ala', 'JJ'),\n",
              "  ('error', 'NN'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('autauga', 'NN'),\n",
              "  ('tried', 'VBD'),\n",
              "  ('hon', 'NN'),\n",
              "  ('b', 'NN'),\n",
              "  ('moore', 'NN'),\n",
              "  ('jun', 'NN'),\n",
              "  ('term', 'NN'),\n",
              "  ('1852', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('cited', 'VBD'),\n",
              "  ('6', 'CD'),\n",
              "  ('dewey', 'NN'),\n",
              "  ('bowman', 'NN'),\n",
              "  ('8', 'CD'),\n",
              "  ('cal', 'JJ'),\n",
              "  ('145', 'CD'),\n",
              "  ('147', 'CD'),\n",
              "  ('cal', 'JJ'),\n",
              "  ('judgment', 'NN'),\n",
              "  ('jacob', 'NN'),\n",
              "  ('cohen', 'NN'),\n",
              "  ('reversed', 'VBD'),\n",
              "  ('following', 'VBG'),\n",
              "  ('reason', 'NN'),\n",
              "  ('finding', 'VBG'),\n",
              "  ('far', 'RB'),\n",
              "  ('cohen', 'NN'),\n",
              "  ('concerned', 'JJ'),\n",
              "  ('jul', 'JJ'),\n",
              "  ('term', 'NN'),\n",
              "  ('1857', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('mentioned', 'VBD'),\n",
              "  ('7', 'CD'),\n",
              "  ('rees', 'NNS'),\n",
              "  ('coat', 'VBP'),\n",
              "  ('65', 'CD'),\n",
              "  ('ala', 'JJ'),\n",
              "  ('256', 'CD'),\n",
              "  ('258', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('trover', 'NN'),\n",
              "  ('conversion', 'NN'),\n",
              "  ('three', 'CD'),\n",
              "  ('bale', 'JJ'),\n",
              "  ('cotton', 'NN'),\n",
              "  ('appeal', 'NN'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('etowah', 'NN'),\n",
              "  ('tried', 'VBD'),\n",
              "  ('hon', 'JJ'),\n",
              "  ('wm', 'NN'),\n",
              "  ('l', 'NN'),\n",
              "  ('whitlock', 'NN'),\n",
              "  ('nov', 'JJ'),\n",
              "  ('term', 'NN'),\n",
              "  ('1880', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('mentioned', 'VBD'),\n",
              "  ('8', 'CD'),\n",
              "  ('edward', 'NN'),\n",
              "  ('thompson', 'NN'),\n",
              "  ('4', 'CD'),\n",
              "  ('sw', 'NN'),\n",
              "  ('913', 'CD'),\n",
              "  ('914', 'CD'),\n",
              "  ('tenn', 'JJ'),\n",
              "  ('appeal', 'NN'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('weakley', 'JJ'),\n",
              "  ('county', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('1887', 'CD'),\n",
              "  ('case', 'NN')],\n",
              " [('9', 'CD'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('subject', 'JJ'),\n",
              "  ('seizure', 'NN'),\n",
              "  ('attachment', 'NN'),\n",
              "  ('103', 'CD'),\n",
              "  ('alr', 'NN'),\n",
              "  ('464', 'CD'),\n",
              "  ('generally', 'RB'),\n",
              "  ('common', 'JJ'),\n",
              "  ('law', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('raised', 'VBN'),\n",
              "  ('annual', 'JJ'),\n",
              "  ('planting', 'NN'),\n",
              "  ('still', 'RB'),\n",
              "  ('attached', 'VBN'),\n",
              "  ('soil', 'NN'),\n",
              "  ('regarded', 'VBD'),\n",
              "  ('personal', 'JJ'),\n",
              "  ('chattel', 'NN'),\n",
              "  ('subject', 'JJ'),\n",
              "  ('seizure', 'NN'),\n",
              "  ('attachment', 'NN'),\n",
              "  ('1936', 'CD'),\n",
              "  ('alr', 'NN')],\n",
              " [('table', 'JJ'),\n",
              "  ('authority', 'NN'),\n",
              "  ('3', 'CD'),\n",
              "  ('treatment', 'NN'),\n",
              "  ('referenced', 'VBD'),\n",
              "  ('title', 'JJ'),\n",
              "  ('type', 'NN'),\n",
              "  ('depth', 'NN'),\n",
              "  ('quoted', 'VBN'),\n",
              "  ('page', 'NN'),\n",
              "  ('number', 'NN')],\n",
              " [('mentioned', 'VBD'),\n",
              "  ('1', 'CD'),\n",
              "  ('austin', 'NN'),\n",
              "  ('sawyer', 'NN'),\n",
              "  ('9', 'CD'),\n",
              "  ('cow', 'NN'),\n",
              "  ('39', 'CD'),\n",
              "  ('nysup', 'JJ'),\n",
              "  ('1828', 'CD'),\n",
              "  ('parol', 'NN'),\n",
              "  ('evidence', 'NN'),\n",
              "  ('admissible', 'JJ'),\n",
              "  ('contradict', 'NN'),\n",
              "  ('substantially', 'RB'),\n",
              "  ('vary', 'JJ'),\n",
              "  ('written', 'VBN'),\n",
              "  ('quitclaimed', 'JJ'),\n",
              "  ('land', 'NN'),\n",
              "  ('w', 'NN'),\n",
              "  ('wheat', 'NN'),\n",
              "  ('growing', 'VBG'),\n",
              "  ('reserving', 'VBG'),\n",
              "  ('case', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('cited', 'VBD'),\n",
              "  ('2', 'CD'),\n",
              "  ('perkins', 'NNS'),\n",
              "  ('mayfield', 'VBD'),\n",
              "  ('5', 'CD'),\n",
              "  ('port', 'NN'),\n",
              "  ('182', 'CD'),\n",
              "  ('ala', 'NN'),\n",
              "  ('1837', 'CD'),\n",
              "  ('writ', 'NN'),\n",
              "  ('error', 'NN'),\n",
              "  ('circuit', 'NN'),\n",
              "  ('tuskaloosa', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('2', 'CD')],\n",
              " [('mentioned', 'VBD'),\n",
              "  ('3', 'CD'),\n",
              "  ('stewart', 'NN'),\n",
              "  ('doughty', 'NN'),\n",
              "  ('9', 'CD'),\n",
              "  ('john', 'NN'),\n",
              "  ('108', 'CD'),\n",
              "  ('nysup', 'JJ'),\n",
              "  ('1812', 'CD'),\n",
              "  ('let', 'NN'),\n",
              "  ('b', 'VB'),\n",
              "  ('farm', 'NN'),\n",
              "  ('six', 'CD'),\n",
              "  ('year', 'NN'),\n",
              "  ('agreed', 'VBD'),\n",
              "  ('render', 'JJR'),\n",
              "  ('yield', 'NN'),\n",
              "  ('pay', 'VBP'),\n",
              "  ('one', 'CD'),\n",
              "  ('half', 'NN'),\n",
              "  ('wheat', 'NN'),\n",
              "  ('rye', 'VBP'),\n",
              "  ('corn', 'NN'),\n",
              "  ('grain', 'NN'),\n",
              "  ('raised', 'VBD'),\n",
              "  ('farm', 'NN'),\n",
              "  ('year', 'NN'),\n",
              "  ('case', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('filing', 'VBG'),\n",
              "  ('filing', 'VBG'),\n",
              "  ('citation', 'NN'),\n",
              "  ('negative', 'JJ'),\n",
              "  ('treatment', 'NN'),\n",
              "  ('negative', 'JJ'),\n",
              "  ('treatment', 'NN'),\n",
              "  ('result', 'NN'),\n",
              "  ('citation', 'NN'),\n",
              "  ('history', 'NN'),\n",
              "  ('history', 'NN'),\n",
              "  ('result', 'NN'),\n",
              "  ('citation', 'NN')]]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yOKp1BNzt5D",
        "outputId": "ee341b1f-6173-451e-ead7-f168947bae59"
      },
      "source": [
        "##  calculate the total number of N(oun), V(erb), Adj(ective),\n",
        "from collections import Counter\n",
        "count = []\n",
        "for tags in pos:\n",
        "  counts = Counter(tag for words, tag in tags)\n",
        "  count.append(counts)\n",
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Counter({'NN': 2}),\n",
              " Counter({'NN': 1}),\n",
              " Counter(),\n",
              " Counter({'NN': 2}),\n",
              " Counter({'CD': 1, 'JJ': 1, 'NN': 1}),\n",
              " Counter({'NN': 1}),\n",
              " Counter({'NN': 4}),\n",
              " Counter({'CD': 1, 'NN': 1, 'VBZ': 1}),\n",
              " Counter({'CC': 1, 'CD': 1, 'JJ': 1, 'NN': 10, 'RB': 1, 'VBG': 1}),\n",
              " Counter({'CD': 1, 'JJ': 1, 'NN': 2}),\n",
              " Counter({'CD': 2, 'JJ': 2, 'NN': 9, 'RB': 1, 'VBG': 2}),\n",
              " Counter({'CD': 43,\n",
              "          'IN': 6,\n",
              "          'JJ': 43,\n",
              "          'JJS': 1,\n",
              "          'MD': 7,\n",
              "          'NN': 140,\n",
              "          'NNS': 10,\n",
              "          'RB': 9,\n",
              "          'RBR': 2,\n",
              "          'VB': 7,\n",
              "          'VBD': 29,\n",
              "          'VBG': 14,\n",
              "          'VBN': 24,\n",
              "          'VBP': 4,\n",
              "          'VBZ': 1}),\n",
              " Counter({'CD': 7,\n",
              "          'JJ': 7,\n",
              "          'NN': 16,\n",
              "          'RB': 1,\n",
              "          'RBR': 1,\n",
              "          'RP': 1,\n",
              "          'VB': 1,\n",
              "          'VBD': 1,\n",
              "          'VBN': 3,\n",
              "          'VBP': 1,\n",
              "          'VBZ': 1,\n",
              "          'WRB': 1}),\n",
              " Counter({'JJR': 1, 'NN': 1, 'NNS': 1}),\n",
              " Counter({'$': 1,\n",
              "          'CC': 1,\n",
              "          'CD': 16,\n",
              "          'IN': 10,\n",
              "          'JJ': 34,\n",
              "          'MD': 9,\n",
              "          'NN': 108,\n",
              "          'NNS': 4,\n",
              "          'RB': 10,\n",
              "          'RBR': 1,\n",
              "          'VB': 7,\n",
              "          'VBD': 14,\n",
              "          'VBG': 9,\n",
              "          'VBN': 16,\n",
              "          'VBP': 4,\n",
              "          'VBZ': 3,\n",
              "          'WP': 1}),\n",
              " Counter({'CD': 9,\n",
              "          'IN': 6,\n",
              "          'JJ': 46,\n",
              "          'JJS': 1,\n",
              "          'MD': 12,\n",
              "          'NN': 124,\n",
              "          'NNS': 3,\n",
              "          'RB': 18,\n",
              "          'VB': 16,\n",
              "          'VBD': 20,\n",
              "          'VBG': 12,\n",
              "          'VBN': 16,\n",
              "          'VBP': 9,\n",
              "          'VBZ': 4}),\n",
              " Counter({'CD': 2,\n",
              "          'IN': 3,\n",
              "          'JJ': 9,\n",
              "          'MD': 4,\n",
              "          'NN': 35,\n",
              "          'NNS': 1,\n",
              "          'RB': 4,\n",
              "          'RP': 1,\n",
              "          'VB': 3,\n",
              "          'VBD': 9,\n",
              "          'VBG': 3,\n",
              "          'VBN': 6,\n",
              "          'VBP': 1}),\n",
              " Counter({'NN': 1, 'VBG': 1}),\n",
              " Counter({'NN': 2}),\n",
              " Counter({'CD': 4,\n",
              "          'IN': 5,\n",
              "          'JJ': 17,\n",
              "          'MD': 9,\n",
              "          'NN': 52,\n",
              "          'RB': 4,\n",
              "          'VB': 9,\n",
              "          'VBD': 4,\n",
              "          'VBG': 6,\n",
              "          'VBN': 4,\n",
              "          'VBZ': 5}),\n",
              " Counter({'CD': 6,\n",
              "          'IN': 3,\n",
              "          'JJ': 10,\n",
              "          'MD': 1,\n",
              "          'NN': 51,\n",
              "          'NNS': 2,\n",
              "          'RB': 2,\n",
              "          'VB': 1,\n",
              "          'VBD': 4,\n",
              "          'VBG': 4,\n",
              "          'VBN': 4,\n",
              "          'VBP': 3,\n",
              "          'VBZ': 1}),\n",
              " Counter({'CD': 1, 'NN': 6, 'NNS': 1, 'VBG': 1}),\n",
              " Counter({'CD': 5, 'JJ': 3, 'NN': 13, 'NNS': 1, 'RB': 1, 'VBD': 3}),\n",
              " Counter({'CD': 5, 'JJ': 1, 'NN': 17, 'VBD': 2}),\n",
              " Counter({'CD': 5, 'JJ': 2, 'NN': 14, 'VBD': 2, 'WRB': 1}),\n",
              " Counter({'CD': 5, 'JJ': 3, 'NN': 12, 'VBD': 2}),\n",
              " Counter({'CD': 5, 'JJ': 2, 'NN': 9, 'NNS': 1, 'VBD': 2, 'VBP': 1}),\n",
              " Counter({'CD': 5, 'JJ': 4, 'NN': 9, 'RB': 1, 'VBD': 2, 'VBG': 2}),\n",
              " Counter({'CD': 6, 'JJ': 4, 'NN': 12, 'NNS': 1, 'VBD': 2, 'VBP': 1}),\n",
              " Counter({'CD': 5, 'JJ': 2, 'MD': 1, 'NN': 7, 'VBD': 1}),\n",
              " Counter({'CD': 4, 'JJ': 5, 'NN': 10, 'RB': 2, 'VBD': 1, 'VBG': 2, 'VBN': 2}),\n",
              " Counter({'CD': 1, 'JJ': 2, 'NN': 6, 'VBD': 1, 'VBN': 1}),\n",
              " Counter({'CD': 10,\n",
              "          'JJ': 4,\n",
              "          'NN': 17,\n",
              "          'NNS': 1,\n",
              "          'RB': 1,\n",
              "          'VBD': 3,\n",
              "          'VBG': 2,\n",
              "          'VBN': 1}),\n",
              " Counter({'CD': 7,\n",
              "          'JJ': 3,\n",
              "          'JJR': 1,\n",
              "          'NN': 23,\n",
              "          'VB': 1,\n",
              "          'VBD': 3,\n",
              "          'VBG': 2,\n",
              "          'VBP': 2})]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Q3VKmn1w0c",
        "outputId": "a9fa4f53-59de-41da-fb06-098d8332f567"
      },
      "source": [
        "!pip install benepar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting benepar\n",
            "  Downloading benepar-0.2.0.tar.gz (33 kB)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.7/dist-packages (from benepar) (3.2.5)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.7/dist-packages (from benepar) (2.2.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from benepar) (1.9.0+cu102)\n",
            "Collecting torch-struct>=0.5\n",
            "  Downloading torch_struct-0.5-py3-none-any.whl (34 kB)\n",
            "Collecting tokenizers>=0.9.4\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 14.6 MB/s \n",
            "\u001b[?25hCollecting transformers[tokenizers,torch]>=4.2.2\n",
            "  Downloading transformers-4.11.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 30.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from benepar) (3.17.3)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2->benepar) (1.15.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (4.62.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.9->benepar) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.9->benepar) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.9->benepar) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.10)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (3.0.12)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 91.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[tokenizers,torch]>=4.2.2->benepar) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (7.1.2)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.2.0-py3-none-any.whl size=37647 sha256=1c3f87bef5268bc906de73ee713583f71413e3c67df25229acbc2546c3813a3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/6f/a3/4d27ce92766bdedd2cbbbedb8857fb7a53534331191cda4994\n",
            "Successfully built benepar\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, torch-struct, sentencepiece, benepar\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed benepar-0.2.0 huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.10.3 torch-struct-0.5 transformers-4.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "jkLqbz464yDQ",
        "outputId": "2e8cda3d-ab61-4c6e-8b12-fa1b9cd2ad53"
      },
      "source": [
        "# Constituency Parsing\n",
        "%tensorflow_version 1.x\n",
        "import benepar\n",
        "benepar.download('benepar_en3')\n",
        "parsing = benepar.parser(\"benepar_en3\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n",
            "[nltk_data]   Package benepar_en3 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-226-78ae1b4037f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbenepar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbenepar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'benepar_en3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mparsing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenepar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"benepar_en3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'benepar' has no attribute 'parser'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z54zVc_H5ZF0",
        "outputId": "38d94249-1e86-408e-aa6e-3edd64155146"
      },
      "source": [
        "# Dependency Parsing\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "kS3gaBeC5cY5",
        "outputId": "a80c6fff-ed86-4723-ce9f-61f6856aedb1"
      },
      "source": [
        "import benepar\n",
        "parser=benepar.Parser(\"benepar_en3\")\n",
        "for statement in train['Lower']: \n",
        "   try:\n",
        "     tree = parser.parse(statement)\n",
        "     print(tree)\n",
        "   except:\n",
        "     print(\"No Parse Tree\")\n",
        "     continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-205-71b5102cccce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbenepar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbenepar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"benepar_en3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstatement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/benepar/integrations/nltk_plugin.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, batch_size, language_code)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mon\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mlanguages\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtreebanks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/benepar/integrations/downloader.py\u001b[0m in \u001b[0;36mload_trained_model\u001b[0;34m(model_name_or_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_chart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChartParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChartParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_trained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/benepar/parse_chart.py\u001b[0m in \u001b[0;36mfrom_trained\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# all tokenizer parameters and a copy of the pre-trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# config (rather than downloading these on-demand).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenepar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             state_dict = torch.load(\n\u001b[1;32m    170\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"benepar_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type_to_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0malbert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mauto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/layoutlm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_layoutlm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayoutLMConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_layoutlm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayoutLMTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/layoutlm/configuration_layoutlm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnnxConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPatchingSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEXTERNAL_DATA_FORMAT_SIZE_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOnnxConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOnnxConfigWithPast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPatchingSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_model_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameterFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_serialized_parameters_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/onnx/convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_torch_onnx_dict_inputs_support_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2043\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;31m# Normalization layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSyncBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LayerNormalization' from 'tensorflow.python.keras.layers.normalization' (/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "AAUN_JlA5cVM",
        "outputId": "b16eea26-2ec8-4775-f0d0-72d28d17be38"
      },
      "source": [
        "# 3.3 Named Entity Recognition\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "for sentence in train['Lower']:\n",
        "  doc=nlp(sentence)\n",
        "  for X in doc.ents:\n",
        "    if X.text and X.label_:\n",
        "      print([(X.text, X.label_)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Lower'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-231-222580c99ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOIT0i70CVxt"
      },
      "source": [
        "Constituency parsing tree: \n",
        "Syntatical parsing is another name for constituency parsing. It is the division of a text into sub-texts or sub-paragraphs, each of which is referred to as a constituent. It specifies a string's or sentence's syntactical structure. These sub-categories of grammar are known as Noun-Phrase(NP) and Verb-Phrase(VP) (VP). Example: It took me over two hours to finish the translation. (S (NP (NP (PRP It)) (VP (VBD took)) (NP (PRP me)) (NP (QR (GGR more) IN than) (CD two)) (NNS hours)) (S(VP (TO to)) (VP (VB translate)) (S(VP (TO to)) (S(VP (TO to)) (S(VP (TO to)) (S(VP (TO to)) (S(VP (TO to))\n",
        "Dependency Parsing Tree:\n",
        " Dependency parsing is the process of assessing a phrase's grammatical structure based on the dependencies between the words in the sentence. Example: Rainy Day The term rainy alters the meaning of the noun weather in this statement. As a result, there is a relationship between rainy days and the weather. As a result, the weather plays the role of a parent, while the rainy season plays the role of a child."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QclIjWNKruUe"
      },
      "source": [
        "# **Question 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_Hon9GxruUe"
      },
      "source": [
        "(20 points) Python Regular Expression.\n",
        "\n",
        "(1) Write a Python program to remove leading zeros from an IP address.\n",
        "\n",
        "ip = \"260.08.094.109\"\n",
        "\n",
        "\n",
        "(2) Write a Python Program to extract all the years from the following sentence.\n",
        "\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIfTYBF1ruUf",
        "outputId": "3d0f5a00-bf60-446c-8073-e2248dd010f3"
      },
      "source": [
        "# Write a Python program to remove leading zeros from an IP address.\n",
        "\n",
        "#ip = \"260.08.094.109\"\n",
        "\n",
        "def excludeleadingzeros(IP):\n",
        "    ipaddress = \".\".join([str(int(a)) for a in IP.split(\".\")])\n",
        "    return ipaddress;\n",
        "IP = \"260.08.094.109\"\n",
        "print(excludeleadingzeros(IP))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260.8.94.109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-vTu6g9B1y7",
        "outputId": "80d8f106-fe6c-4a0b-8207-7aa6abc5df39"
      },
      "source": [
        "#Write a Python Program to extract all the years from the following sentence.\n",
        "list=[]                                 #empty list\n",
        "flag=0                                   #flag \n",
        "m=\"\"                                    #empty string\n",
        "\n",
        "for k in data:                          #for loop\n",
        "    if k=='2':                          #if k is 2 then flag 1\n",
        "        flag=1\n",
        "        \n",
        "    if not(k.isdigit()) and flag==1:    #if k is not a digit and flag is 1 \n",
        "        flag=0                          \n",
        "        \n",
        "    if k.isdigit() and flag==1:          \n",
        "        m+=k                            #adding  k to string m\n",
        "        \n",
        "    if m!=\"\" and k==\" \":                \n",
        "        list.append(int(m))             #append m as integer to list\n",
        "        m=\"\"                            \n",
        "print(list)                              #printing years list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2010, 2010, 2019]\n"
          ]
        }
      ]
    }
  ]
}